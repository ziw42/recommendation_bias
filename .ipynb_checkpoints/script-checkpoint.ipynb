{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b9ae0cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x152bdfb2270>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "import MF\n",
    "import math\n",
    "from sklearn import cluster\n",
    "from operator import itemgetter\n",
    "from math import log\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import utility\n",
    "from scipy.sparse import csr_matrix, rand as sprand\n",
    "from tqdm import tqdm\n",
    "from MF import MF\n",
    "import VAE\n",
    "import os\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9be74523",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Unpickling user and item matrices\n",
    "\n",
    "test_like = np.load(\"./data/user_vali_like.npy\", allow_pickle=True)\n",
    "train_like = np.load(\"./data/user_train_like.npy\", allow_pickle=True)\n",
    "\n",
    "### mtx_item[I]: the list of users that like item I\n",
    "### mtx_user[U]: the list of items that user U like\n",
    "\n",
    "with open(\"./data/item\", \"rb\") as f: \n",
    "    mtx_item = pickle.load(f)\n",
    "\n",
    "with open(\"./data/user\", \"rb\") as f:\n",
    "    mtx_user = pickle.load(f)\n",
    "    \n",
    "### Read the trained model\n",
    "model = torch.load(\"./data/save.pt\")\n",
    "# Item matrix\n",
    "Q = model.item_factors.weight.H.tolist()\n",
    "# User matrix\n",
    "P = model.user_factors.weight.H.tolist()\n",
    "\n",
    "P = np.array(P)\n",
    "Q = np.array(Q)\n",
    "\n",
    "### Predicted matrix\n",
    "Rec = np.matmul(P.T, Q)\n",
    "\n",
    "\n",
    "### The test_like and train_like lists, but for item\n",
    "### test_like_item[I]: the users who like item I in the test set\n",
    "### train_like_item[I]: the users who like item I in the train set\n",
    "test_like_item = []\n",
    "for t in range(Rec.shape[1]):\n",
    "    test_like_item.append([])\n",
    "i = 0\n",
    "for t in test_like:\n",
    "    for tt in t:\n",
    "        test_like_item[tt].append(i)\n",
    "    i += 1\n",
    "\n",
    "train_like_item = []\n",
    "for t in range(Rec.shape[0]):\n",
    "    train_like_item.append([])\n",
    "i = 0\n",
    "for t in train_like:\n",
    "    for tt in t:\n",
    "        train_like_item[tt].append(i)\n",
    "    i += 1\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97ef8fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "Rec_train = []\n",
    "for t in range(Rec.shape[0]):\n",
    "    row = [0]*Rec.shape[1]\n",
    "    for item in train_like[t]:\n",
    "        row[item] = 1\n",
    "    Rec_train.append(row)\n",
    "Rec_train = np.array(Rec_train)\n",
    "\n",
    "J_similar = Rec_train.dot(Rec_train.T)\n",
    "for t in range(J_similar.shape[0]):\n",
    "    J_similar[t][t] = 0\n",
    "J_similar = J_similar.astype(\"float32\")\n",
    "train_like_len = []\n",
    "for t in train_like:\n",
    "    train_like_len.append(len(t))\n",
    "    \n",
    "for i in range(Rec_train.shape[0]):\n",
    "    for j in range(i):\n",
    "        if J_similar[i][j] != 0:\n",
    "            J_similar[i][j] /= (train_like_len[i] + train_like_len[j])\n",
    "\n",
    "Rec_train_item = Rec_train.T\n",
    "J_similar_item = Rec_train_item.dot(Rec_train_item.T)\n",
    "for t in range(J_similar_item.shape[0]):\n",
    "    J_similar_item[t][t] = 0\n",
    "J_similar_item = J_similar_item.astype(\"float32\")\n",
    "train_like_item_len = []\n",
    "for t in train_like_item:\n",
    "    train_like_item_len.append(len(t))\n",
    "            \n",
    "for i in range(J_similar_item.shape[0]):\n",
    "    for j in range(i):\n",
    "        if J_similar_item[i][j] != 0:\n",
    "            J_similar_item[i][j] /= (train_like_item_len[i] + train_like_item_len[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2801048",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions for metrices\n",
    "def get_activeness(user):\n",
    "    return len(train_like[user])\n",
    "\n",
    "def get_popularity(item):\n",
    "    return len(train_like_item[item])\n",
    "\n",
    "def get_user_mainstreamness(user):\n",
    "    ### mainstreamness == jacarrd similarity\n",
    "    return(sum(J_similar[user])/(J_similar.shape[0]-1))\n",
    "\n",
    "def get_item_mainstreamness(item):\n",
    "    ### mainstreamness == jacarrd similarity\n",
    "    return(sum(J_similar_item[item])/(J_similar_item.shape[1]-1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3122e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate the metrices\n",
    "\n",
    "activeness = []\n",
    "user_mainstreamness = []\n",
    "for t in range(Rec.shape[0]):\n",
    "    activeness.append(get_activeness(t))\n",
    "    user_mainstreamness.append((get_user_mainstreamness(t)))\n",
    "                               \n",
    "popularity = []\n",
    "item_mainstreamness = []\n",
    "for t in range(Rec.shape[1]):\n",
    "    popularity.append(get_popularity(t))\n",
    "    item_mainstreamness.append((get_item_mainstreamness(t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fa70bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### _sort[0] = values\n",
    "### _sort[1] = indexs\n",
    "\n",
    "act_sort = (np.sort(np.array(activeness)), np.argsort(np.array(activeness)))\n",
    "usrmain_sort = (np.sort(np.array(user_mainstreamness)), np.argsort(np.array(user_mainstreamness)))\n",
    "pop_sort = (np.sort(np.array(popularity)), np.argsort(np.array(popularity)))\n",
    "itmmain_sort = (np.sort(np.array(item_mainstreamness)), np.argsort(np.array(item_mainstreamness)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c826654e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./data/activeness.npy\", activeness)\n",
    "np.save(\"./data/user_mainstreamness.npy\", user_mainstreamness)\n",
    "np.save(\"./data/popularity.npy\", popularity)\n",
    "np.save(\"./data/item_mainstreamness.npy\", item_mainstreamness)\n",
    "\n",
    "np.save(\"./data/act_sort.npy\", act_sort)\n",
    "np.save(\"./data/usrmain_sort.npy\", usrmain_sort)\n",
    "np.save(\"./data/pop_sort.npy\", pop_sort)\n",
    "np.save(\"./data/itmmain_sort.npy\", itmmain_sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0804d5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load the metrics from disk\n",
    "act_sort = np.load(\"./data/act_sort.npy\")\n",
    "pop_sort = np.load(\"./data/pop_sort.npy\")\n",
    "usrmain_sort = np.load(\"./data/usrmain_sort.npy\")\n",
    "itmmain_sort = np.load(\"./data/itmmain_sort.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79a52523",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions for calculating NDCG@K, performance, and average rank\n",
    "\n",
    "num_u = Rec.shape[0]\n",
    "like = train_like\n",
    "for i in range(num_u):\n",
    "    Rec[i, like[i]] = -100000.0\n",
    "\n",
    "### No train set in Rec_sort!!!\n",
    "### Pretty quick even we sort all users and items\n",
    "Rec_sort = []\n",
    "for t in Rec:\n",
    "    num = t.tolist().count(-100000.0)\n",
    "    tt = np.argsort(t)[::-1]\n",
    "    tt = tt[0:(len(tt)-num)]\n",
    "    Rec_sort.append(tt)\n",
    "\n",
    "def NDCG_at_k(predicted_list, ground_truth, k):\n",
    "    dcg_value = [(v / log(i + 1 + 1, 2)) for i, v in enumerate(predicted_list[:k])]\n",
    "    dcg = np.sum(dcg_value)\n",
    "    if len(ground_truth) < k:\n",
    "        ground_truth += [0 for i in range(k - len(ground_truth))]\n",
    "    idcg_value = [(v / log(i + 1 + 1, 2)) for i, v in enumerate(ground_truth[:k])]\n",
    "    idcg = np.sum(idcg_value)\n",
    "    return dcg / idcg\n",
    "\n",
    "def get_ndcg_ave(user):\n",
    "    k_set = [1,5,10,20]\n",
    "    u_pred = Rec[user, :]\n",
    "    top15_item_idx_no_train = np.argpartition(u_pred, -k_set[-1])[-k_set[-1]:]\n",
    "    top15 = (np.array([top15_item_idx_no_train, u_pred[top15_item_idx_no_train]])).T\n",
    "    top15 = sorted(top15, key=itemgetter(1), reverse=True)\n",
    "    new_user_prediction = top15\n",
    "    test = test_like[user]\n",
    "\n",
    "    dcg_list = []\n",
    "\n",
    "    # compute the number of true positive items at top k\n",
    "    rank_sum = 0\n",
    "    count = 0\n",
    "    for i in range(k_set[3]):\n",
    "        if new_user_prediction[i][0] in test:\n",
    "            rank_sum += (i+1)\n",
    "            count += 1\n",
    "            dcg_list.append(1)\n",
    "        else:\n",
    "            dcg_list.append(0)\n",
    "\n",
    "    # calculate NDCG@k\n",
    "    idcg_list = [1 for i in range(len(test))]\n",
    "    ndcg_tmp_15 = NDCG_at_k(dcg_list, idcg_list, k_set[3])\n",
    "    ### Calculate average rank of test items\n",
    "    ### Notice: only test items in the top 20 count\n",
    "    if rank_sum!= 0:\n",
    "        ave_rank = rank_sum/count\n",
    "    else:\n",
    "        ave_rank = 100000\n",
    "    \n",
    "    return ndcg_tmp_15, ave_rank\n",
    "\n",
    "\n",
    "\n",
    "def get_performance_ave(item):\n",
    "### !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "### get performance@20 after 20 is 0\n",
    "    k = 20\n",
    "    test = test_like_item[item]\n",
    "    ### Number of the users who likes this item\n",
    "    hit_usr = len(test)\n",
    "    ### Top of the fraction\n",
    "    a = 0\n",
    "    \n",
    "    rank_sum = 0\n",
    "    count = 0\n",
    "    for t in range(k):\n",
    "        if t < hit_usr:\n",
    "            ranklist = Rec_sort[test[t]]\n",
    "            rank = ranklist.tolist().index(item)+1\n",
    "            rank_sum += rank\n",
    "            count += 1\n",
    "            a += 1/math.log(rank+2, 2)\n",
    "        else:\n",
    "            a += 0\n",
    "    if count != 0:\n",
    "        performance = a/min(hit_usr, k) ### a/min(hit_usr, 20) or a/20?\n",
    "        ave_rank = rank_sum/count\n",
    "    else:\n",
    "        performance = 0\n",
    "        ave_rank = 100000\n",
    "    \n",
    "    return performance, ave_rank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f877d4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_user():\n",
    "    user_num = Rec.shape[0]\n",
    "    NDCG = []\n",
    "    Ave_rank = []\n",
    "    for t in range(user_num):\n",
    "        ndcg_, ave_rank_ = get_ndcg_ave(t)\n",
    "        NDCG.append(ndcg_)\n",
    "        Ave_rank.append(ave_rank_)\n",
    "    return NDCG, Ave_rank\n",
    "\n",
    "def evaluate_item():\n",
    "    item_num = Rec.shape[1]\n",
    "    Performance = []\n",
    "    Ave_rank = []\n",
    "    for t in range(item_num):\n",
    "        performance_, ave_rank_ = get_performance_ave(t)\n",
    "        Performance.append(performance_)\n",
    "        Ave_rank.append(ave_rank_)\n",
    "    return Performance, Ave_rank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0ae6479",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zian\\AppData\\Local\\Temp\\ipykernel_28568\\492530454.py:24: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return dcg / idcg\n"
     ]
    }
   ],
   "source": [
    "NDCG, Ave_rank_user = evaluate_user()\n",
    "Performance, Ave_rank_item = evaluate_item()\n",
    "NDCG = np.array(NDCG)\n",
    "Ave_rank_user = np.array(Ave_rank_user)\n",
    "Performance = np.array(Performance)\n",
    "Ave_rank_item = np.array(Ave_rank_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6cef7b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "### K is the number of groups\n",
    "k = 5\n",
    "results = {\"usrmain\":{\"NDCG\":[], \"Ave_rank\":[], \"Ave_mtc\":[], \"Metric\":[]}, \"activeness\":{\"NDCG\":[], \"Ave_rank\":[], \"Ave_mtc\":[], \"Metric\":[]}, \n",
    "           \"itmmain\":{\"Performance\":[], \"Ave_rank\":[], \"Ave_mtc\":[], \"Metric\":[]}, \"popularity\":{\"Performance\":[], \"Ave_rank\":[], \"Ave_mtc\":[], \"Metric\":[]}}\n",
    "num_user = Rec.shape[0]\n",
    "bt_user = int(num_user/k)\n",
    "num_item = Rec.shape[1]\n",
    "bt_item = int(num_item/k)\n",
    "for i in range(k):\n",
    "    if i == k-1:\n",
    "        idxs = usrmain_sort[1][i*bt_user::]\n",
    "        idxs2 = act_sort[1][i*bt_user::]\n",
    "        idxs3 = itmmain_sort[1][i*bt_item::]\n",
    "        idxs4 = pop_sort[1][i*bt_item::]\n",
    "    else:\n",
    "        idxs = usrmain_sort[1][i*bt_user:(i+1)*bt_user]\n",
    "        idxs2 = act_sort[1][i*bt_user:(i+1)*bt_user]\n",
    "        idxs3 = itmmain_sort[1][i*bt_item:(i+1)*bt_item]\n",
    "        idxs4 = pop_sort[1][i*bt_item:(i+1)*bt_item]\n",
    "    results[\"usrmain\"][\"NDCG\"].append(NDCG[idxs])\n",
    "    results[\"usrmain\"][\"Ave_rank\"].append(Ave_rank_user[idxs])\n",
    "    results[\"usrmain\"][\"Ave_mtc\"].append(np.mean(usrmain_sort[0][idxs]))\n",
    "    results[\"usrmain\"][\"Metric\"].append(usrmain_sort[0][idxs])\n",
    "    results[\"activeness\"][\"NDCG\"].append(NDCG[idxs2])\n",
    "    results[\"activeness\"][\"Ave_rank\"].append(Ave_rank_user[idxs2])\n",
    "    results[\"activeness\"][\"Ave_mtc\"].append(np.mean(act_sort[0][idxs2]))\n",
    "    results[\"activeness\"][\"Metric\"].append(act_sort[0][idxs2])\n",
    "    results[\"itmmain\"][\"Performance\"].append(Performance[idxs3])\n",
    "    results[\"itmmain\"][\"Ave_rank\"].append(Ave_rank_item[idxs3])\n",
    "    results[\"itmmain\"][\"Ave_mtc\"].append(np.mean(itmmain_sort[0][idxs3]))\n",
    "    results[\"itmmain\"][\"Metric\"].append(itmmain_sort[0][idxs3])\n",
    "    results[\"popularity\"][\"Performance\"].append(Performance[idxs4])\n",
    "    results[\"popularity\"][\"Ave_rank\"].append(Ave_rank_item[idxs4])\n",
    "    results[\"popularity\"][\"Ave_mtc\"].append(np.mean(pop_sort[0][idxs4]))\n",
    "    results[\"popularity\"][\"Metric\"].append(pop_sort[0][idxs4])\n",
    "    \n",
    "\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3bb716c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Convert results to dataframe\n",
    "### Save the dataframes\n",
    "df = {\"NDCG\": [], \"Ave_rank\":[], \"metric\": [], \"group\": [], \"ave_metric\": []}\n",
    "for group in range(k):\n",
    "    for t in results[\"usrmain\"][\"NDCG\"][group]:\n",
    "        df[\"NDCG\"].append(t)\n",
    "    for t in results[\"usrmain\"][\"Ave_rank\"][group]:\n",
    "        df[\"Ave_rank\"].append(t)\n",
    "    ave_metric_ = results[\"usrmain\"][\"Ave_mtc\"][group]\n",
    "    for t in results[\"usrmain\"][\"Metric\"][group]:\n",
    "        df[\"metric\"].append(t)\n",
    "        df[\"group\"].append(group)\n",
    "        df[\"ave_metric\"].append(ave_metric_)\n",
    "df = pd.DataFrame(df)\n",
    "df.to_csv(\"./data/user main.csv\")\n",
    "\n",
    "df = {\"NDCG\": [], \"Ave_rank\":[], \"metric\": [], \"group\": [], \"ave_metric\": []}\n",
    "for group in range(k):\n",
    "    for t in results[\"activeness\"][\"NDCG\"][group]:\n",
    "        df[\"NDCG\"].append(t)\n",
    "    for t in results[\"activeness\"][\"Ave_rank\"][group]:\n",
    "        df[\"Ave_rank\"].append(t)\n",
    "    ave_metric_ = results[\"activeness\"][\"Ave_mtc\"][group]\n",
    "    for t in results[\"activeness\"][\"Metric\"][group]:\n",
    "        df[\"metric\"].append(t)\n",
    "        df[\"group\"].append(group)\n",
    "        df[\"ave_metric\"].append(ave_metric_)\n",
    "df = pd.DataFrame(df)\n",
    "df.to_csv(\"./data/user act.csv\")\n",
    "\n",
    "df = {\"Performance\": [], \"Ave_rank\":[], \"metric\": [], \"group\": [], \"ave_metric\": []}\n",
    "for group in range(k):\n",
    "    for t in results[\"itmmain\"][\"Performance\"][group]:\n",
    "        df[\"Performance\"].append(t)\n",
    "    for t in results[\"itmmain\"][\"Ave_rank\"][group]:\n",
    "        df[\"Ave_rank\"].append(t)\n",
    "    ave_metric_ = results[\"itmmain\"][\"Ave_mtc\"][group]\n",
    "    for t in results[\"itmmain\"][\"Metric\"][group]:\n",
    "        df[\"metric\"].append(t)\n",
    "        df[\"group\"].append(group)\n",
    "        df[\"ave_metric\"].append(ave_metric_)\n",
    "df = pd.DataFrame(df)\n",
    "df.to_csv(\"./data/item main.csv\")\n",
    "\n",
    "df = {\"Performance\": [], \"Ave_rank\":[], \"metric\": [], \"group\": [], \"ave_metric\": []}\n",
    "for group in range(k):\n",
    "    for t in results[\"popularity\"][\"Performance\"][group]:\n",
    "        df[\"Performance\"].append(t)\n",
    "    for t in results[\"popularity\"][\"Ave_rank\"][group]:\n",
    "        df[\"Ave_rank\"].append(t)\n",
    "    ave_metric_ = results[\"popularity\"][\"Ave_mtc\"][group]\n",
    "    for t in results[\"popularity\"][\"Metric\"][group]:\n",
    "        df[\"metric\"].append(t)\n",
    "        df[\"group\"].append(group)\n",
    "        df[\"ave_metric\"].append(ave_metric_)\n",
    "df = pd.DataFrame(df)\n",
    "df.to_csv(\"./data/item pop.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
