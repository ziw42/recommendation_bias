{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b9ae0cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x200b11ca1b0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "import MF\n",
    "import math\n",
    "from sklearn import cluster\n",
    "from operator import itemgetter\n",
    "from math import log\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import utility\n",
    "from scipy.sparse import csr_matrix, rand as sprand\n",
    "from tqdm import tqdm\n",
    "from MF import MF\n",
    "import VAE\n",
    "import os\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9be74523",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Unpickling user and item matrices\n",
    "\n",
    "### mtx_item[I]: the list of users that like item I\n",
    "### mtx_user[U]: the list of items that user U like\n",
    "\n",
    "with open(\"./data/item\", \"rb\") as f: \n",
    "    mtx_item = pickle.load(f)\n",
    "\n",
    "with open(\"./data/user\", \"rb\") as f:\n",
    "    mtx_user = pickle.load(f)\n",
    "    \n",
    "### Read the trained model\n",
    "model = torch.load(\"./data/save.pt\")\n",
    "# Item matrix\n",
    "Q = model.item_factors.weight.H.tolist()\n",
    "# User matrix\n",
    "P = model.user_factors.weight.H.tolist()\n",
    "\n",
    "P = np.array(P)\n",
    "Q = np.array(Q)\n",
    "\n",
    "### Predicted matrix\n",
    "Rec = np.matmul(P.T, Q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2801048",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions for metrices\n",
    "def get_activeness(user):\n",
    "    return len(mtx_user[user])\n",
    "\n",
    "def get_popularity(item):\n",
    "    return len(mtx_item[item])\n",
    "\n",
    "def get_user_mainstreamness(user):\n",
    "    ### mainstreamness == jacarrd similarity\n",
    "    j_sim = 0\n",
    "    for t in range(len(mtx_user)):\n",
    "        if t == user:\n",
    "            continue\n",
    "        dul_list = [x for x in mtx_user[user] if x in mtx_user[t]]\n",
    "        l = len(dul_list)\n",
    "        j_sim += l/(len(mtx_user[user]+mtx_user[t])-l)\n",
    "    j_sim /= len(mtx_user)-1\n",
    "    return(j_sim)\n",
    "\n",
    "def get_item_mainstreamness(item):\n",
    "    ### mainstreamness == jacarrd similarity\n",
    "    j_sim = 0\n",
    "    for t in range(len(mtx_item)):\n",
    "        if t == item:\n",
    "            continue\n",
    "        dul_list = [x for x in mtx_item[item] if x in mtx_item[t]]\n",
    "        l = len(dul_list)\n",
    "        num_sim = (len(mtx_item[item]+mtx_item[t])-l)\n",
    "        if num_sim == 0:\n",
    "            j_sim += 1\n",
    "        else:\n",
    "            j_sim += l/num_sim\n",
    "    j_sim /= len(mtx_item)-1\n",
    "    return(j_sim)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3122e12",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [4], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m6040\u001b[39m):\n\u001b[0;32m      6\u001b[0m     activeness\u001b[38;5;241m.\u001b[39mappend(get_activeness(t))\n\u001b[1;32m----> 7\u001b[0m     user_mainstreamness\u001b[38;5;241m.\u001b[39mappend((\u001b[43mget_user_mainstreamness\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[0;32m      9\u001b[0m popularity \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     10\u001b[0m item_mainstreamness \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[1;32mIn [3], line 14\u001b[0m, in \u001b[0;36mget_user_mainstreamness\u001b[1;34m(user)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m t \u001b[38;5;241m==\u001b[39m user:\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m dul_list \u001b[38;5;241m=\u001b[39m [x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m mtx_user[user] \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m mtx_user[t]]\n\u001b[0;32m     15\u001b[0m l \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(dul_list)\n\u001b[0;32m     16\u001b[0m j_sim \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m l\u001b[38;5;241m/\u001b[39m(\u001b[38;5;28mlen\u001b[39m(mtx_user[user]\u001b[38;5;241m+\u001b[39mmtx_user[t])\u001b[38;5;241m-\u001b[39ml)\n",
      "Cell \u001b[1;32mIn [3], line 14\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m t \u001b[38;5;241m==\u001b[39m user:\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m dul_list \u001b[38;5;241m=\u001b[39m [x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m mtx_user[user] \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m mtx_user[\u001b[43mt\u001b[49m]]\n\u001b[0;32m     15\u001b[0m l \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(dul_list)\n\u001b[0;32m     16\u001b[0m j_sim \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m l\u001b[38;5;241m/\u001b[39m(\u001b[38;5;28mlen\u001b[39m(mtx_user[user]\u001b[38;5;241m+\u001b[39mmtx_user[t])\u001b[38;5;241m-\u001b[39ml)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Calculate the metrices\n",
    "\n",
    "activeness = []\n",
    "user_mainstreamness = []\n",
    "for t in range(6040):\n",
    "    activeness.append(get_activeness(t))\n",
    "    user_mainstreamness.append((get_user_mainstreamness(t)))\n",
    "                               \n",
    "popularity = []\n",
    "item_mainstreamness = []\n",
    "for t in range(3706):\n",
    "    popularity.append(get_popularity(t))\n",
    "    item_mainstreamness.append((get_item_mainstreamness(t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa70bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### _sort[0] = values\n",
    "### _sort[1] = indexs\n",
    "\n",
    "act_sort = (np.sort(np.array(activeness)), np.argsort(np.array(activeness)))\n",
    "usrmain_sort = (np.sort(np.array(user_mainstreamness)), np.argsort(np.array(user_mainstreamness)))\n",
    "pop_sort = (np.sort(np.array(popularity)), np.argsort(np.array(popularity)))\n",
    "itmmain_sort = (np.sort(np.array(item_mainstreamness)), np.argsort(np.array(item_mainstreamness)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c826654e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./data/activeness.npy\", activeness)\n",
    "np.save(\"./data/user_mainstreamness.npy\", user_mainstreamness)\n",
    "np.save(\"./data/popularity.npy\", popularity)\n",
    "np.save(\"./data/item_mainstreamness.npy\", item_mainstreamness)\n",
    "\n",
    "np.save(\"./data/act_sort.npy\", act_sort)\n",
    "np.save(\"./data/usrmain_sort.npy\", usrmain_sort)\n",
    "np.save(\"./data/pop_sort.npy\", pop_sort)\n",
    "np.save(\"./data/itmmain_sort.npy\", itmmain_sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0804d5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load the metrics from disk\n",
    "act_sort = np.load(\"./data/act_sort.npy\")\n",
    "pop_sort = np.load(\"./data/pop_sort.npy\")\n",
    "usrmain_sort = np.load(\"./data/usrmain_sort.npy\")\n",
    "itmmain_sort = np.load(\"./data/itmmain_sort.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "072840aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_like = np.load(\"./data/user_vali_like.npy\", allow_pickle=True)\n",
    "train_like = np.load(\"./data/user_train_like.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd161dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "### The test_like and train_like lists, but for item\n",
    "### test_like_item[I]: the users who like item I in the test set\n",
    "### train_like_item[I]: the users who like item I in the train set\n",
    "test_like_item = []\n",
    "for t in range(Rec.shape[1]):\n",
    "    test_like_item.append([])\n",
    "i = 0\n",
    "for t in test_like:\n",
    "    for tt in t:\n",
    "        test_like_item[tt].append(i)\n",
    "    i += 1\n",
    "\n",
    "train_like_item = []\n",
    "for t in range(Rec.shape[0]):\n",
    "    train_like_item.append([])\n",
    "i = 0\n",
    "for t in train_like:\n",
    "    for tt in t:\n",
    "        train_like_item[tt].append(i)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79a52523",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions for calculating NDCG@K and performance\n",
    "\n",
    "num_u = Rec.shape[1]\n",
    "like = train_like\n",
    "for i in range(num_u):\n",
    "    Rec[i, like[i]] = -100000.0\n",
    "    \n",
    "Rec_sort = []\n",
    "for t in Rec:\n",
    "    num = t.tolist().count(-100000.0)\n",
    "    tt = np.argsort(t)[::-1]\n",
    "    tt = tt[0:(len(tt)-num)]\n",
    "    Rec_sort.append(tt)\n",
    "\n",
    "def NDCG_at_k(predicted_list, ground_truth, k):\n",
    "    dcg_value = [(v / log(i + 1 + 1, 2)) for i, v in enumerate(predicted_list[:k])]\n",
    "    dcg = np.sum(dcg_value)\n",
    "    if len(ground_truth) < k:\n",
    "        ground_truth += [0 for i in range(k - len(ground_truth))]\n",
    "    idcg_value = [(v / log(i + 1 + 1, 2)) for i, v in enumerate(ground_truth[:k])]\n",
    "    idcg = np.sum(idcg_value)\n",
    "    return dcg / idcg\n",
    "\n",
    "def get_ndcg(user):\n",
    "    k_set = [1,5,10,20]\n",
    "    u_pred = Rec[user, :]\n",
    "    top15_item_idx_no_train = np.argpartition(u_pred, -k_set[-1])[-k_set[-1]:]\n",
    "    top15 = (np.array([top15_item_idx_no_train, u_pred[top15_item_idx_no_train]])).T\n",
    "    top15 = sorted(top15, key=itemgetter(1), reverse=True)\n",
    "    new_user_prediction = top15\n",
    "    test = test_like[user]\n",
    "\n",
    "    dcg_list = []\n",
    "\n",
    "    # compute the number of true positive items at top k\n",
    "    count_1, count_5, count_10, count_15 = 0, 0, 0, 0\n",
    "    for i in range(k_set[3]):\n",
    "        if i < k_set[0] and new_user_prediction[i][0] in test:\n",
    "            count_1 += 1.0\n",
    "        if i < k_set[1] and new_user_prediction[i][0] in test:\n",
    "            count_5 += 1.0\n",
    "        if i < k_set[2] and new_user_prediction[i][0] in test:\n",
    "            count_10 += 1.0\n",
    "        if new_user_prediction[i][0] in test:\n",
    "            count_15 += 1.0\n",
    "            dcg_list.append(1)\n",
    "        else:\n",
    "            dcg_list.append(0)\n",
    "\n",
    "    # calculate NDCG@k\n",
    "    idcg_list = [1 for i in range(len(test))]\n",
    "    ndcg_tmp_1 = NDCG_at_k(dcg_list, idcg_list, k_set[0])\n",
    "    ndcg_tmp_5 = NDCG_at_k(dcg_list, idcg_list, k_set[1])\n",
    "    ndcg_tmp_10 = NDCG_at_k(dcg_list, idcg_list, k_set[2])\n",
    "    ndcg_tmp_15 = NDCG_at_k(dcg_list, idcg_list, k_set[3])\n",
    "\n",
    "    return ndcg_tmp_15\n",
    "\n",
    "\n",
    "\n",
    "def get_performance(item):\n",
    "    test = test_like_item[item]\n",
    "    ### Number of the users who likes this item\n",
    "    hit_usr = len(test)\n",
    "    ### Top of the fraction\n",
    "    a = 0\n",
    "    for t in test:\n",
    "        ### Column here\n",
    "        ranklist = Rec_sort[t]\n",
    "        rank = ranklist.tolist().index(item)+1\n",
    "        a += 1/math.log(rank+2, 2)\n",
    "    if hit_usr != 0:\n",
    "        performance = a/hit_usr\n",
    "    else:\n",
    "        performance = 0\n",
    "    return performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "afae222e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_user(mtc, k):\n",
    "    ### mtc should be index of the users\n",
    "    ### K for NDCG@K\n",
    "    k_ndcg = 15\n",
    "    \n",
    "    ### Divide users into k groups evenly\n",
    "    bt = int(len(mtc[0])/k)\n",
    "    labels = []\n",
    "    for t in range(k):\n",
    "        if t == k-1:\n",
    "            labels[t*bt::] = [t]*(len(mtc[0])-(k-1)*bt)\n",
    "        else:\n",
    "            labels[t*bt:t*(bt+1)] = [t]*bt\n",
    "        \n",
    "    NDCG = {}\n",
    "    ave_mtc = {}\n",
    "    m = {}\n",
    "    for t in range(k):\n",
    "        NDCG[t] = []\n",
    "        ave_mtc[t] = 0\n",
    "        n = 0\n",
    "        m[t] = []\n",
    "        for ii in range(len(labels)):\n",
    "            if labels[ii] == t:\n",
    "                NDCG[t].append(get_ndcg(mtc[1][ii]))\n",
    "                ave_mtc[t] += mtc[0][ii]\n",
    "                n += 1\n",
    "                m[t].append(mtc[0][ii])\n",
    "        ave_mtc[t] /= n\n",
    "    return NDCG, ave_mtc, m\n",
    "\n",
    "def evaluate_item(mtc, k):\n",
    "    bt = int(len(mtc[0])/k)\n",
    "    labels = []\n",
    "    for t in range(k):\n",
    "        if t == k-1:\n",
    "            labels[t*bt::] = [t]*(len(mtc[0])-(k-1)*bt)\n",
    "        else:\n",
    "            labels[t*bt:t*(bt+1)] = [t]*bt\n",
    "    \n",
    "    performance = {}\n",
    "    ave_mtc = {}\n",
    "    m = {}\n",
    "    for t in range(k):\n",
    "        performance[t] = []\n",
    "        ave_mtc[t] = 0\n",
    "        n = 0\n",
    "        m[t] = []\n",
    "        for ii in range(len(labels)):\n",
    "            if labels[ii] == t:\n",
    "                performance[t].append(get_performance(mtc[1][ii]))\n",
    "                ave_mtc[t] += mtc[0][ii]\n",
    "                n += 1\n",
    "                m[t].append(mtc[0][ii])\n",
    "        ave_mtc[t] /= n\n",
    "    return performance, ave_mtc, m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7c507475",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zian\\AppData\\Local\\Temp\\ipykernel_27800\\2726008027.py:22: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return dcg / idcg\n"
     ]
    }
   ],
   "source": [
    "groups = 5\n",
    "res_usrmain, ave_usrmain, m_usrmain = evaluate_user(usrmain_sort, groups)\n",
    "res_act, ave_act, m_act = evaluate_user(act_sort, groups)\n",
    "res_itmmain, ave_itmmain, m_itmmain = evaluate_item(itmmain_sort, groups)\n",
    "res_pop, ave_pop, m_pop = evaluate_item(pop_sort, groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4ec9ba70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.18883775e-05, 1.26104644e-05, 1.70429042e-05, ...,\n",
       "        7.17443696e-02, 7.19049935e-02, 7.28420562e-02]),\n",
       " array([3176, 3623, 3678, ...,  792,  200,  715], dtype=int64))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itmmain_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3bb716c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Convert results to dataframe\n",
    "def to_df(r, a, m):\n",
    "    df = {\"result\": [], \"metric\": [], \"group\": [], \"ave_metric\": []}\n",
    "    k = len(r)\n",
    "    for t in range(k):\n",
    "        l = len(r[t])\n",
    "        for tt in range(l):\n",
    "            df[\"result\"].append(r[t][tt])\n",
    "            df[\"metric\"].append(m[t][tt])\n",
    "            df[\"group\"].append(t)\n",
    "            df[\"ave_metric\"].append(a[t])\n",
    "    df = pd.DataFrame(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3d5f7b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save the dataframes\n",
    "df = to_df(res_pop, ave_pop, m_pop)\n",
    "df.to_csv(\"./data/item pop.csv\")\n",
    "df = to_df(res_usrmain, ave_usrmain, m_usrmain)\n",
    "df.to_csv(\"./data/user main.csv\")\n",
    "df = to_df(res_itmmain, ave_itmmain, m_itmmain)\n",
    "df.to_csv(\"./data/item main.csv\")\n",
    "df = to_df(res_act, ave_act, m_act)\n",
    "df.to_csv(\"./data/user act.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf5d0379",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
