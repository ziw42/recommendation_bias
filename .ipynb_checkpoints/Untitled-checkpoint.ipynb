{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b9ae0cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x24b8da54b10>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "import MF\n",
    "import math\n",
    "from sklearn import cluster\n",
    "from operator import itemgetter\n",
    "from math import log\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import utility\n",
    "from scipy.sparse import csr_matrix, rand as sprand\n",
    "from tqdm import tqdm\n",
    "from MF import MF\n",
    "import VAE\n",
    "import os\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9be74523",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'shape' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [7], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m### Predicted matrix\u001b[39;00m\n\u001b[0;32m     23\u001b[0m Rec \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmatmul(P\u001b[38;5;241m.\u001b[39mT, Q)\n\u001b[1;32m---> 25\u001b[0m \u001b[43mshape\u001b[49m(Rec)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'shape' is not defined"
     ]
    }
   ],
   "source": [
    "### Unpickling user and item matrices\n",
    "\n",
    "### mtx_item[I]: the list of users that like item I\n",
    "### mtx_user[U]: the list of items that user U like\n",
    "\n",
    "with open(\"./data/item\", \"rb\") as f: \n",
    "    mtx_item = pickle.load(f)\n",
    "\n",
    "with open(\"./data/user\", \"rb\") as f:\n",
    "    mtx_user = pickle.load(f)\n",
    "    \n",
    "### Read the trained model\n",
    "model = torch.load(\"./data/save.pt\")\n",
    "# Item matrix\n",
    "Q = model.item_factors.weight.H.tolist()\n",
    "# User matrix\n",
    "P = model.user_factors.weight.H.tolist()\n",
    "\n",
    "P = np.array(P)\n",
    "Q = np.array(Q)\n",
    "\n",
    "### Predicted matrix\n",
    "Rec = np.matmul(P.T, Q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2801048",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions for metrices\n",
    "def get_activeness(user):\n",
    "    return len(mtx_user[user])\n",
    "\n",
    "def get_popularity(item):\n",
    "    return len(mtx_item[item])\n",
    "\n",
    "def get_user_mainstreamness(user):\n",
    "    ### mainstreamness == jacarrd similarity\n",
    "    j_sim = 0\n",
    "    for t in range(len(mtx_user)):\n",
    "        if t == user:\n",
    "            continue\n",
    "        dul_list = [x for x in mtx_user[user] if x in mtx_user[t]]\n",
    "        l = len(dul_list)\n",
    "        j_sim += l/(len(mtx_user[user]+mtx_user[t])-l)\n",
    "    j_sim /= len(mtx_user)-1\n",
    "    return(j_sim)\n",
    "\n",
    "def get_item_mainstreamness(item):\n",
    "    ### mainstreamness == jacarrd similarity\n",
    "    j_sim = 0\n",
    "    for t in range(len(mtx_item)):\n",
    "        if t == item:\n",
    "            continue\n",
    "        dul_list = [x for x in mtx_item[item] if x in mtx_item[t]]\n",
    "        l = len(dul_list)\n",
    "        num_sim = (len(mtx_item[item]+mtx_item[t])-l)\n",
    "        if num_sim == 0:\n",
    "            j_sim += 1\n",
    "        else:\n",
    "            j_sim += l/num_sim\n",
    "    j_sim /= len(mtx_item)-1\n",
    "    return(j_sim)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3122e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate the metrices\n",
    "\n",
    "activeness = []\n",
    "user_mainstreamness = []\n",
    "for t in range(6040):\n",
    "    activeness.append(get_activeness(t))\n",
    "    user_mainstreamness.append((get_user_mainstreamness(t)))\n",
    "                               \n",
    "popularity = []\n",
    "item_mainstreamness = []\n",
    "for t in range(3706):\n",
    "    popularity.append(get_popularity(t))\n",
    "    item_mainstreamness.append((get_item_mainstreamness(t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa70bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_sort = np.sort(np.array(activeness))\n",
    "usrmain_sort = np.sort(np.array(user_mainstreamness))\n",
    "pop_sort = np.sort(np.array(popularity))\n",
    "itmmain_sort = np.sort(np.array(item_mainstreamness))\n",
    "print(act_sort)\n",
    "print(usrmain_sort)\n",
    "print(pop_sort)\n",
    "print(itmmain_sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c826654e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./data/activeness.npy\", activeness)\n",
    "np.save(\"./data/user_mainstreamness.npy\", user_mainstreamness)\n",
    "np.save(\"./data/popularity.npy\", popularity)\n",
    "np.save(\"./data/item_mainstreamness.npy\", item_mainstreamness)\n",
    "\n",
    "np.save(\"./data/act_sort.npy\", act_sort)\n",
    "np.save(\"./data/usrmain_sort.npy\", usrmain_sort)\n",
    "np.save(\"./data/pop_sort.npy\", pop_sort)\n",
    "np.save(\"./data/itmmain_sort.npy\", itmmain_sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0804d5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load the metrics from disk\n",
    "act_sort = np.load(\"./data/act_sort.npy\")\n",
    "pop_sort = np.load(\"./data/pop_sort.npy\")\n",
    "usrmain_sort = np.load(\"./data/usrmain_sort.npy\")\n",
    "itmmain_sort = np.load(\"./data/itmmain_sort.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "072840aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_like = np.load(\"./data/user_vali_like.npy\", allow_pickle=True)\n",
    "train_like = np.load(\"./data/user_train_like.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd161dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "### The test_like and train_like lists, but for item\n",
    "### test_like_item[I]: the users who like item I in the test set\n",
    "### train_like_item[I]: the users who like item I in the train set\n",
    "test_like_item = []\n",
    "for t in range(Rec.shape[1]):\n",
    "    test_like_item.append([])\n",
    "i = 0\n",
    "for t in test_like:\n",
    "    for tt in t:\n",
    "        test_like_item[tt].append(i)\n",
    "    i += 1\n",
    "\n",
    "train_like_item = []\n",
    "for t in range(Rec.shape[0]):\n",
    "    train_like_item.append([])\n",
    "i = 0\n",
    "for t in train_like:\n",
    "    for tt in t:\n",
    "        train_like_item[tt].append(i)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a52523",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions for calculating NDCG@K and performance\n",
    "\n",
    "num_u = Rec.shape[1]\n",
    "like = train_like\n",
    "for i in range(num_u):\n",
    "    Rec[i, like[i]] = -100000.0\n",
    "    \n",
    "Rec_sort = []\n",
    "for t in Rec:\n",
    "    num = t.tolist().count(-100000.0)\n",
    "    tt = np.argsort(t)[::-1]\n",
    "    tt = tt[0:(len(tt)-num)]\n",
    "    Rec_sort.append(tt)\n",
    "\n",
    "def NDCG_at_k(predicted_list, ground_truth, k):\n",
    "    dcg_value = [(v / log(i + 1 + 1, 2)) for i, v in enumerate(predicted_list[:k])]\n",
    "    dcg = np.sum(dcg_value)\n",
    "    if len(ground_truth) < k:\n",
    "        ground_truth += [0 for i in range(k - len(ground_truth))]\n",
    "    idcg_value = [(v / log(i + 1 + 1, 2)) for i, v in enumerate(ground_truth[:k])]\n",
    "    idcg = np.sum(idcg_value)\n",
    "    return dcg / idcg\n",
    "\n",
    "def get_ndcg(user):\n",
    "    k_set = [1,5,10,20]\n",
    "    u_pred = Rec[u, :]\n",
    "    top15_item_idx_no_train = np.argpartition(u_pred, -k_set[-1])[-k_set[-1]:]\n",
    "    top15 = (np.array([top15_item_idx_no_train, u_pred[top15_item_idx_no_train]])).T\n",
    "    top15 = sorted(top15, key=itemgetter(1), reverse=True)\n",
    "    new_user_prediction = top15\n",
    "    test = test_like[user]\n",
    "\n",
    "    dcg_list = []\n",
    "\n",
    "    # compute the number of true positive items at top k\n",
    "    count_1, count_5, count_10, count_15 = 0, 0, 0, 0\n",
    "    for i in range(k_set[3]):\n",
    "        if i < k_set[0] and new_user_prediction[i][0] in test:\n",
    "            count_1 += 1.0\n",
    "        if i < k_set[1] and new_user_prediction[i][0] in test:\n",
    "            count_5 += 1.0\n",
    "        if i < k_set[2] and new_user_prediction[i][0] in test:\n",
    "            count_10 += 1.0\n",
    "        if new_user_prediction[i][0] in test:\n",
    "            count_15 += 1.0\n",
    "            dcg_list.append(1)\n",
    "        else:\n",
    "            dcg_list.append(0)\n",
    "\n",
    "    # calculate NDCG@k\n",
    "    idcg_list = [1 for i in range(len(test))]\n",
    "    ndcg_tmp_1 = NDCG_at_k(dcg_list, idcg_list, k_set[0])\n",
    "    ndcg_tmp_5 = NDCG_at_k(dcg_list, idcg_list, k_set[1])\n",
    "    ndcg_tmp_10 = NDCG_at_k(dcg_list, idcg_list, k_set[2])\n",
    "    ndcg_tmp_15 = NDCG_at_k(dcg_list, idcg_list, k_set[3])\n",
    "\n",
    "    return ndcg_tmp_15\n",
    "\n",
    "\n",
    "\n",
    "def get_performance(item):\n",
    "    test = test_like_item[item]\n",
    "    ### Number of the users who likes this item\n",
    "    hit_usr = len(test)\n",
    "    ### Top of the fraction\n",
    "    a = 0\n",
    "    for t in test:\n",
    "        ### Column here\n",
    "        ranklist = Rec_sort[t]\n",
    "        rank = ranklist.tolist().index(item)+1\n",
    "        a += 1/math.log(rank+2, 2)\n",
    "    if hit_usr != 0:\n",
    "        performance = a/hit_usr\n",
    "    else:\n",
    "        performance = 0\n",
    "    return performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afae222e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_user(mtc, k):\n",
    "    ### mtc should be index of the users\n",
    "    ### K for NDCG@K\n",
    "    k_ndcg = 15\n",
    "    \n",
    "    ### Divide users into k groups evenly\n",
    "    bt = int(len(mtc)/k)\n",
    "    labels = []\n",
    "    for t in range(k):\n",
    "        if t == k-1:\n",
    "            labels[t*bt::] = [t]*(len(mtc)-(k-1)*bt)\n",
    "        else:\n",
    "            labels[t*bt:t*(bt+1)] = [t]*bt\n",
    "        \n",
    "    NDCG = {}\n",
    "    ave_mtc = {}\n",
    "    m = {}\n",
    "    for t in range(k):\n",
    "        NDCG[t] = []\n",
    "        ave_mtc[t] = 0\n",
    "        n = 0\n",
    "        m[t] = []\n",
    "        for ii in range(len(labels)):\n",
    "            if labels[ii] == t:\n",
    "                NDCG[t].append(get_ndcg(ii))\n",
    "                ave_mtc[t] += mtc[ii]\n",
    "                n += 1\n",
    "                m[t].append(mtc[ii])\n",
    "        ave_mtc[t] /= n\n",
    "    return NDCG, ave_mtc, m\n",
    "\n",
    "def evaluate_item(mtc, k):\n",
    "    clusters = cluster.KMeans(n_clusters = k).fit(mtc.reshape(-1, 1))\n",
    "    performance = {}\n",
    "    ave_mtc = {}\n",
    "    m = {}\n",
    "    for t in range(k):\n",
    "        performance[t] = []\n",
    "        ave_mtc[t] = 0\n",
    "        n = 0\n",
    "        m[t] = []\n",
    "        for ii in range(len(clusters.labels_)):\n",
    "            if clusters.labels_[ii] == t:\n",
    "                performance[t].append(get_performance(ii))\n",
    "                ave_mtc[t] += mtc[ii]\n",
    "                n += 1\n",
    "                m[t].append(mtc[ii])\n",
    "        ave_mtc[t] /= n\n",
    "    return performance, ave_mtc, m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c507475",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_usrmain, ave_usrmain, m_usrmain = evaluate_user(usrmain_sort, 10)\n",
    "res_act, ave_act, m_act = evaluate_user(act_sort, 10)\n",
    "res_itmmain, ave_itmmain, m_itmmain = evaluate_item(itmmain_sort, 10)\n",
    "res_pop, ave_pop, m_pop = evaluate_item(pop_sort, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb716c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Convert results to dataframe\n",
    "def to_df(r, a, m):\n",
    "    df = {\"result\": [], \"metric\": [], \"group\": [], \"ave_metric\": []}\n",
    "    k = len(r)\n",
    "    for t in range(k):\n",
    "        l = len(r[t])\n",
    "        for tt in range(l):\n",
    "            df[\"result\"].append(r[t][tt])\n",
    "            df[\"metric\"].append(m[t][tt])\n",
    "            df[\"group\"].append(t)\n",
    "            df[\"ave_metric\"].append(a[t])\n",
    "    df = pd.DataFrame(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5f7b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save the dataframes\n",
    "df = to_df(res_pop, ave_pop, m_pop)\n",
    "df.to_csv(\"./data/item pop.csv\")\n",
    "df = to_df(res_usrmain, ave_usrmain, m_usrmain)\n",
    "df.to_csv(\"./data/user main.csv\")\n",
    "df = to_df(res_itmmain, ave_itmmain, m_itmmain)\n",
    "df.to_csv(\"./data/item main.csv\")\n",
    "df = to_df(res_act, ave_act, m_act)\n",
    "df.to_csv(\"./data/user act.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5d0379",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
